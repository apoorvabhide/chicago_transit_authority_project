myString <- "Hello, World!"
print (myString)
?factor
.libPaths()
install.packages("xml", dependencies = TRUE)
install.packages("XML", dependencies = TRUE)
library(XML)
.libPaths("~/R library")
install.packages("XML", dependencies = TRUE)
library(XML)
acc_05_07 <- read.csv("~/R Work/accidents_2005_to_2007.csv", header = TRUE, stringsAsFactors = FALSE)
acc_09_11 <- read.csv("~/R Work/accidents_2009_to_2011.csv", header = TRUE, stringsAsFactors = FALSE)
acc_12_14 <- read.csv("~/R Work/accidents_2012_to_2014.csv", header = TRUE, stringsAsFactors = FALSE)
acc_05_11 <- rbind(acc_05_07, acc_09_11)
acc <- rbind(acc_05_11, acc_12_14)
View(acc)
View(acc)
View(head(acc))
rm(acc$Location_Easting_OSGR, acc$Location_Northing_OSGR)
rm(acc$Location_Easting_OSGR)
acc$Location_Easting_OSGR <- NULL
acc$Location_Northing_OSGR <- NULL
head(acc)
install.packages("isdals",dependencies = TRUE)
library(isdals)
data(bodyfat)
attach(bodyfat)
cor( cbind(Fat, Triceps,Thigh,Midarm) )
data(Auto)
install.packages("Auto")
install.packages("ISLR", dependencies = TRUE)
library(ISLR)
data("Weekly")
rm(list=ls())
data("Weekly")
summary("Weekly")
str("Weekly")
summary(Weekly)
View(Weekly)
log.fit <- glm(Direction ~ Lag1 + Lag2 + Lag3+ Lag4 + Lag5 + Volume, family = Binomial)
log.fit <- glm(Direction ~ Lag1 + Lag2 + Lag3+ Lag4 + Lag5 + Volume, family = binomial)
log.fit <- glm(Direction ~ Lag1 + Lag2 + Lag3+ Lag4 + Lag5 + Volume, data = Weekly ,family = binomial)
summary(log.fit)
View(log.fit)
install.packages("caret")
summary(Weekly)
library(caret)
confusionMatrix(log.fit$y, Weekly$Direction)
summary(log.fit$y)
confusionMatrix(as.factor(log.fit$y), as.factor(Weekly$Direction))
summary(Weekly$Direction)
View(Weekly)
View(log.fit)
table(log.fit$y)
rm(list = ls())
rm(list = ls())
lyrics <- read.csv("/home/ab/Downloads/Datasets for analysis/taylor_swift_lyrics/taylor_swift_lyrics.csv", header = TRUE, stringsAsFactors = FALSE)
View(lyrics)
songs <- aggregate(lyric ~ artist + album + track_title + track_n + year, lyrics, function(x){paste0(x, sep = " ")})
View(songs)
songs[9]
songs[9,6]
lines_by_song <- aggregate(line ~ track_title + album + year, lyrics, max)
View(lines_by_song)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
write.csv(songs, file = "/home/ab/Downloads/Datasets for analysis/taylor_swift_lyrics/songs.csv")
install.packages("quanteda", dependencies = TRUE)
View(lyrics)
#Some basic EDA:
#Average lines/song, by year
tracks <- aggregate(track_n ~ album + year, lyrics, max)
View(tracks)
View(songs)
View(lines_by_song)
#Some basic EDA:
lyrics$length <- str_count(lyrics$lyric,"\\S+"
#Some basic EDA:
lyrics$length <- str_count(lyrics$lyric,"\\S+"
)
#Some basic EDA:
lyrics$length <- str_count(lyrics$lyric,"\\S+")
#Some basic EDA:
#Checking the word counts
lyrics$wc <- sapply(strsplit(lyrics$lyric, " "), length)
View(lyrics)
lyrics[is.na(lyrics$wc),]
lyrics[is.na(lyrics$wc)]
wc_over_time <- aggregate(wc ~ year, lyrics, sum)
View(wc_over_time)
library(ggplot2)
lps <- aggregate(line ~ year, lines_by_song, avg)
lps <- aggregate(line ~ year, lines_by_song, mean)
View(lps)
p <- ggplot(lines_by_song, aes(year, line))
p+geom_bar(stat = "identity")
#Some basic EDA:
#Checking the word counts
lines_by_song <- aggregate(line ~ track_title + track_n + album + year, lyrics, max)
songs_per_album <- aggregate(track_n ~ album + year, lyrics, max)
View(songs_per_album)
View(lines_by_song)
lines_by_song <- merge(lines_by_song, songs_per_album, all = TRUE)
p+geom_bar(stat = "identity", aes(fill = type))
p+geom_bar(stat = "identity", aes(fill = line))
p <- ggplot(lps, aes(year, line))
p+geom_bar(stat = "identity", color = 'cyan')
p+geom_bar(stat = "identity", fill = 'cyan')
p+geom_bar(stat = "identity", fill = 'blue')
p+geom_bar(stat = "identity", fill = 'blue') + labs(title = "Lines per song over the years", y = "lines per song", x = "Year")
p+geom_bar(stat = "identity", fill = 'blue') + labs(title = "Lines per song over the years", y = "Lines per Song", x = "Year")
hist(lyrics$wc)
wc_song <- aggregate(wc~ track_title + album + year, lyrics, sum)
hist(wc_song)
View(wc_song)
hist(wc_song$wc)
install.packages("quanteda", dependencies = TRUE)
install.packages("spacyr", dependencies = TRUE)
hist(wc_song$wc)
#Okay, most songs have around 400 words.
prop.table(table(lyrics))
View(songs)
install.packages("keras", dependencies = TRUE)
install.packages("keras", dependencies = TRUE)
#Okay, most songs have around 400 words.
library(keras)
library(stringr)
taylor_swift <-
path <- get_file(
"taylor_swift_lyrics.txt",
origin = "~/R Work/tylor_swift_lyrics.txt"
)
taylor_swift <-
path <- get_file(
"taylor_swift_lyrics.txt",
)
taylor_swift <-
path <- get_file(
"taylor_swift_lyrics.txt")
install.packages("readtext")
library(readtext)
install.packages("readtext", dependencies = TRUE)
install.packages("readtext", dependencies = TRUE)
install.packages("readtext", dependencies = TRUE)
install.packages("readtext", dependencies = TRUE)
rm(list = ls()
)
library(knitr)
knit(input="~/R Work/ipl_mom_markdown.Rmd", output = "~/R Work/ipl_mom_markdown.md")
knit(input="~/R Work/ipl_mom_markdown.Rmd", output = "~/R Work/ipl_mom_markdown.md")
knit(input="~/R Work/ipl_man_of_the_match/ipl_mom_markdown.Rmd", output = "~/R Work/ipl_man_of_the_match/ipl_mom_markdown.md")
knit(input="~/R Work/ipl_man_of_the_match/ipl_mom_markdown.Rmd", output = "~/R Work/ipl_man_of_the_match/ipl_mom_markdown.md")
rm(list = ls())
############################################################
##  I: Forecasting bus ridership by route                 ##
##  Apoorva Bhide                                         ##
##  16 August 2018                                        ##
############################################################
setwd('~/R Work/chicago_transit_data/')
rides_by_route <- read.csv('cta-ridership-bus-routes-daily-totals-by-route.csv', header = TRUE, stringsAsFactors = FALSE)
rides_by_route$date <- as.Date(rides_by_route$date)
#Generally, what are the busy routes?
routes <- aggregate(rides ~ route, rides_by_route, sum)
#Maybe weekday busy routes are different from weekend busy routes
rides_by_route_12_18 <- rides_by_route[rides_by_route$date >= "2012-01-01" & rides_by_route$date <= "2018-03-31",]
route_9 <-rides_by_route_12_18[rides_by_route_12_18$route == 9,]
plot(ts((diff(rides_by_route_12_18$rides[rides_by_route_12_18$route == 9]))))
#What is the average traffic on every route?
avg_traffic_weekday <- aggregate(rides ~ route, rides_by_route_12_18[rides_by_route_12_18$daytype == 'U',], mean)
avg_traffic_weekend <- aggregate(rides ~ route, rides_by_route_12_18[rides_by_route_12_18$daytype == 'W'| rides_by_route_12_18$daytype == 'A',], mean)
avg_traffic <- merge(avg_traffic_weekday, avg_traffic_weekend, by = 'route')
plot(x = avg_traffic$rides.x, y = avg_traffic$rides.y, xlim = c(0,25000), ylim = c(0,25000), xlab = 'Rides on weekdays', ylab = 'Rides on weekends')
#Create year-wise split of routes
rides_by_route_12_18$year <- strftime(rides_by_route_12_18$date, format = '%Y')
route_yr <- aggregate(rides ~ route + year, rides_by_route_12_18, sum)
library(reshape)
route_year <- cast(route_yr, route ~ year)
write.csv(route_year,'route_year.csv')
route_year <- route_year[,-c(3:7)]
route_year$diff <- route_year$`2012` - route_year$`2018`
route_year$diff <- route_year$diff/route_year$`2012`
route_year <- na.omit(route_year)
plot(x = route_year$`2012`, y = route_year$diff, xlab = 'Rides in 2012', ylab = 'Difference in rides, 2012-2018', ylim = c(0.4,1))
hist(route_year$diff)
#Only keeping the top 10 routes by total ridership between 2012-2018
routes_top <- aggregate(rides ~ route, rides_by_route_12_18, sum)
routes_top <- head(routes_top[order(-routes_top$rides),], 10)
#The busiest route in terms of volume seems to be route 79
route_79 <- rides_by_route_12_18[rides_by_route_12_18$route == 79,]
#First, reserve validation set as Feb 2018 and test as March 2018
validation_79 <- route_79[route_79$date >= '2018-02-01' & route_79$date <= '2018-02-28',]
test_79 <- route_79[route_79$date >= '2018-03-01' & route_79$date <= '2018-03-31',]
#Let's only consider data from 2015 onwards
route_79 <- route_79[route_79$date>='2015-01-01' & route_79$date <= '2018-01-31',]
plot(ts(route_79$rides))
#There is a downward trend in the data, and it also has more variance at the beginning than later
ts_79 <- ts(route_79$rides)
ts_79 <- diff(log(ts_79))
plot(ts_79)
#Let's make a forecast, using simple exponential smoothing
ses_79 <- HoltWinters(ts_79,alpha = 0.1, beta = FALSE, gamma = FALSE)
install.packages("forecast")
library(forecast)
#There is a downward trend in the data, and it also has more variance at the beginning than later
ts_79 <- msts(route_79$rides, seasonal.periods = c(7, 365.25))
plot(ts_79)
ts_79 <- diff(log(ts_79))
plot(ts_79)
#Let's make a forecast, using simple exponential smoothing
ses_79 <- tbats(ts_79)
feb_pred <- forecast(ses_79)
View(feb_pred)
plot(feb_pred)
rm(list = ls())
############################################################
##  I: Forecasting bus ridership by route                 ##
##  Apoorva Bhide                                         ##
##  16 August 2018                                        ##
############################################################
setwd('~/R Work/chicago_transit_data/')
rides_by_route <- read.csv('cta-ridership-bus-routes-daily-totals-by-route.csv', header = TRUE, stringsAsFactors = FALSE)
rides_by_route$date <- as.Date(rides_by_route$date)
rides_by_route$month <- strftime(rides_by_route$date, '%m')
View(rides_by_route)
rides_by_route$year <- strftime(rides_by_route$date, '%Y')
rides_by_month <- aggregate(rides ~ route + month + year, rides_by_route, sum)
View(rides_by_route)
View(rides_by_month)
#Only consider data since 2008
rides_by_month <- rides_by_month[rides_by_month$year >= 2008,]
View(rides_by_month)
plot(ts(rides_by_month$month[rides_by_month$route == 79,]))
plot(ts(rides_by_month$month[rides_by_month$route == 79]))
plot(ts(rides_by_month$rides[rides_by_month$route == 79]))
plot(ts(rides_by_month$rides[rides_by_month$route == 9]))
route_79 <- rides_by_month[rides_by_month$route == 79,]
plot(ts(route_79$rides))
plot(ts(log(route_79$rides)))
plot(ts(diff(route_79$rides)))
validation_79 <- route_79[route_79$month == 2 & route_79$year == 2018,]
View(route_79)
validation_79 <- route_79[route_79$month == 02 & route_79$year == 2018,]
validation_79 <- route_79[route_79$month == '02' & route_79$year == 2018,]
View(validation_79)
test_79 <- route_79[route_79$month == '03' & route_79$year == 2018,]
View(test_79)
route_79 <- route_79[-validation_79,]
route_79 <- route_79[-validation_79]
route_79 <- route_79[!((route_79$month == '02'|route_79$month == '03') & route_79$year == 2018)]
route_79 <- route_79[!((route_79$month == '02'|route_79$month == '03') & route_79$year == 2018),]
View(route_79)
rm(list = ls())
############################################################
##  I: Forecasting bus ridership by route                 ##
##  Apoorva Bhide                                         ##
##  16 August 2018                                        ##
############################################################
setwd('~/R Work/chicago_transit_data/')
rides_by_route <- read.csv('cta-ridership-bus-routes-daily-totals-by-route.csv', header = TRUE, stringsAsFactors = FALSE)
rides_by_route$date <- as.Date(rides_by_route$date)
rides_by_route$month <- strftime(rides_by_route$date, '%m')
rides_by_route$year <- strftime(rides_by_route$date, '%Y')
rides_by_month_train <- aggregate(rides ~ route + month + year, rides_by_route[rides_by_route$date <= '2017-01-01',], sum)
rides_by_month_train <- aggregate(rides ~ route + month + year, rides_by_route[rides_by_route$date < '2017-01-01',], sum)
rides_by_month_test <- aggregate(rides ~ route + month + year, rides_by_route[rides_by_route$date >= '2017-01-01',], sum)
route_79_train <- rides_by_month_train[rides_by_month_train$route == 79,]
route_79_test <- rides_by_month_test[rides_by_month_test$route == 79,]
View(route_79_test)
plot(ts(route_79_train))
plot(ts(route_79_train$year))
plot(ts(route_79_train$rides))
#Basic Arima
ts_79_train <- ts(route_79_train$rides)
plot(ts_79_train)
plot(diff(ts_79_train))
ts_79_train <- diff(ts_79_train)
plot(ts_79_train)
acf(ts_79_train)
pacf(ts_79_train)
acf(ts_79_train)
pacf(ts_79_train)
autoarima <- auto.arima(ts_79_train)
View(autoarima)
autoarima[["arma"]]
plot(forecast(autoarima, h = 15))
prediction <- forecast(autoarima, h = 15)
View(prediction)
plot(prediction)
acf(ts_79_train)
pacf(ts_79_train)
for(i in 1:3)
{
for(j in 0:1)
{
for(k in 1:4)
{
arima_model <- arima(ts_79_train,order = (i,j,k))
print("AIC for model ARIMA(")
print(i," ", j," ",k,")")
print(AIC(arima_model))
}
}
}
i <- 0
j <- 0
k <- 0
for(i in 1:3)
{
for(j in 0:1)
{
for(k in 1:4)
{
arima_model <- arima(ts_79_train,order = (i,j,k))
print("AIC for model ARIMA(")
print(i," ", j," ",k,")")
print(AIC(arima_model))
}
}
}
for(i in 1:3)
{
for(j in 0:1)
{
for(k in 1:4)
{
arima_model <- arima(ts_79_train,order = c(i,j,k))
print(i)
print(j)
print(k)
print(AIC(arima_model))
}
}
}
models <- data.frame()
models <- rbind(models,data.frame(cbind(i,j,k,AIC(arima_model))))
for(i in 1:3)
{
for(j in 0:1)
{
for(k in 1:4)
{
arima_model <- arima(ts_79_train,order = c(i,j,k))
models <- rbind(models,data.frame(cbind(i,j,k,AIC(arima_model))))
}
}
}
View(models)
#ARIMA(2,1,4) gives the best with the data
model <- arima(2,1,4)
#ARIMA(2,1,4) gives the best with the data
model <- arima(ts_79_train, c(2,1,4))
acf(resid(model))
Box.test(resid(model),type="Ljung-Box")
plot(resid(model))
acf(resid(model))
#There is autocorrelation in the residuals. Hmmm.
#Trying ARIMA(3,0,3) instead
model_2 <- arima(ts_79_train, c(3,0,3))
acf(resid(model_2))
Box.test(resid(model),type="Ljung-Box")
Box.test(resid(model_2),type="Ljung-Box")
#This one looks good. Ljung-Box gives a p-value of 0.8572
forecast(model_2,h = 15)
#This one looks good. Ljung-Box gives a p-value of 0.8572
plot(forecast(model_2,h = 15))
ts_79_train[-1,]
tail(ts_79_train,1)
model_2_fc <- forecast(model_2,h = 15)
View(model_2_fc)
plot(route_79_test$rides)
plot(ts(route_79_test$rides))
plot(diff(ts(route_79_test$rides)))
ts_79_test <- diff(ts(route_79_test$rides)))
ts_79_test <- diff(ts(route_79_test$rides))
model_acc <- accuracy(model_2_fc$mean, ts_79_test)
forecast(model_2,h = 15)
model_2_fc$method
model_2_fc$mean
ts_79_test
model_acc <- accuracy(model_2_fc$mean, as.numeric(ts_79_test))
View(model_acc)
forecast(autoarima,h = 15)
auto_fc <- forecast(autoarima,h = 15)
accuracy(auto_fc$mean, as.numeric(ts_79_test))
accuracy(model_2_fc$mean, as.numeric(ts_79_test))
